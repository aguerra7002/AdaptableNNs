{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from adaptable import AdaptableNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference After Increase 1: tensor(0., grad_fn=<CopyBackwards>)\n",
      "Difference After Decrease 1: tensor(0., grad_fn=<CopyBackwards>)\n",
      "Difference After Decrease 2: tensor(0.0399, grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "# Set seed properly\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Create the AdaptableNet\n",
    "test_net = AdaptableNet(12, 5, hidden_size=[7, 10])\n",
    "# Create some fake data\n",
    "test_data = torch.Tensor(np.random.random((4, 12)))\n",
    "# Generate some fake output\n",
    "test_output = test_net(test_data)\n",
    "\n",
    "# Increase the size of the first hidden layer of the net\n",
    "test_net.increase_hidden_size(0)\n",
    "\n",
    "print(\"Difference After Increase 1:\", torch.norm(test_output - test_net(test_data)))\n",
    "\n",
    "# Immediately decrease the size of the first hidden layer of the net \n",
    "# Note: this first decrease will be a trivial operation since we are just undoing the increase from above\n",
    "test_net.decrease_hidden_size(0)\n",
    "\n",
    "print(\"Difference After Decrease 1:\", torch.norm(test_output - test_net(test_data)))\n",
    "\n",
    "# Decrease the size of the first hidden layer of the net AGAIN. \n",
    "# This will be a nontrivial decrease, as it has to get rid of some nonzero weights\n",
    "test_net.decrease_hidden_size(0)\n",
    "\n",
    "print(\"Difference After Decrease 2:\", torch.norm(test_output - test_net(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 1: Seeing what method of decreasing the hidden size is in general best. May need to come back to try new methods of doing this since the current methods are very heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will store our \"losses\" for each mode\n",
    "losses = np.zeros((4, 1000))\n",
    "\n",
    "# For different seeds\n",
    "for i in range(1000):\n",
    "    # For each mode\n",
    "    for mode in range(4):\n",
    "        # Set the seeds\n",
    "        np.random.seed(i)\n",
    "        torch.manual_seed(i)\n",
    "        # Initialize Net\n",
    "        test_net = AdaptableNet(12, 5, hidden_size=[10,])\n",
    "        # Generate data\n",
    "        test_data = torch.Tensor(np.random.random((4, 12)))\n",
    "        # Generate output\n",
    "        test_output = test_net(test_data)\n",
    "        # Decrease the size\n",
    "        test_net.decrease_hidden_size(0, mode=mode)\n",
    "        # Compute the norm of the difference in the output\n",
    "        losses[mode, i] = torch.norm(test_output - test_net(test_data))\n",
    "        \n",
    "means = np.mean(losses, axis=1)\n",
    "print(\"Method 0 avg. loss:\", means[0])\n",
    "print(\"Method 1 avg. loss:\", means[1])\n",
    "print(\"Method 2 avg. loss:\", means[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
